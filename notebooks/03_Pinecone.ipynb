{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "357c97c9",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "```python\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv_path = dotenv.find_dotenv()\n",
    "dotenv.load_dotenv(dotenv_path)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a27e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv_path = dotenv.find_dotenv()\n",
    "dotenv.load_dotenv(dotenv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "153047ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_community.embeddings import CohereEmbeddings\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from pinecone import Pinecone as PineconeClient\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffc9b4f4-64d4-4266-9889-54db90e00ee9",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this is required since Juypyter notebook is not async by default.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27624157",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index 'quickstart' not found in your Pinecone project. Did you mean one of the following indexes: semantic-search-fast",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m pinecone \u001b[38;5;241m=\u001b[39m PineconeClient(api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m7207a70b-81a9-47c0-9135-c5a5330da435\u001b[39m\u001b[38;5;124m\"\u001b[39m, environment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mus-east-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m CohereEmbeddings(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilingual-22-12\u001b[39m\u001b[38;5;124m\"\u001b[39m, cohere_api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnUnqjugboR7rLilAR9AHBzq4Bh5rM0SscbbFxXtJ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mPinecone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_existing_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquickstart\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m retriever \u001b[38;5;241m=\u001b[39m vectorstore\u001b[38;5;241m.\u001b[39mas_retriever()\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_community/vectorstores/pinecone.py:456\u001b[0m, in \u001b[0;36mPinecone.from_existing_index\u001b[0;34m(cls, index_name, embedding, text_key, namespace, pool_threads)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_existing_index\u001b[39m(\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    453\u001b[0m     pool_threads: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m    454\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Pinecone:\n\u001b[1;32m    455\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load pinecone vectorstore from index name.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m     pinecone_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pinecone_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(pinecone_index, embedding, text_key, namespace)\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/langchain_community/vectorstores/pinecone.py:383\u001b[0m, in \u001b[0;36mPinecone.get_pinecone_index\u001b[0;34m(cls, index_name, pool_threads)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    378\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo active indexes found in your Pinecone project, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mare you sure you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre using the right Pinecone API key and Environment? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease double check your Pinecone dashboard.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    381\u001b[0m     )\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not found in your Pinecone project. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    385\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid you mean one of the following indexes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(index_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    386\u001b[0m     )\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m index\n",
      "\u001b[0;31mValueError\u001b[0m: Index 'quickstart' not found in your Pinecone project. Did you mean one of the following indexes: semantic-search-fast"
     ]
    }
   ],
   "source": [
    "# Init\n",
    "pinecone = PineconeClient(api_key=\"7207a70b-81a9-47c0-9135-c5a5330da435\", environment=\"us-east-1\")\n",
    "embeddings = CohereEmbeddings(model=\"multilingual-22-12\", cohere_api_key=\"nUnqjugboR7rLilAR9AHBzq4Bh5rM0SscbbFxXtJ\")\n",
    "vectorstore = Pinecone.from_existing_index(index_name=\"quickstart\", embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fca250",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac46a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=\"/teamspace/studios/this_studio/retrieval-augmented-generation/data/\"\n",
    "loader = DirectoryLoader(docs, glob=\"./*.txt\", loader_cls=TextLoader)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b48a301",
   "metadata": {},
   "source": [
    "## Split document into nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a537bc0-78ee-4dda-a43f-60fd80062df6",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "934b4203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "223e2d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"that's that's clearly happened um there's also economies of economies of scale and building simpler simpler\\ndevices that do one thing incredibly well um especially with consumer devices\\nthough it is it's consumer consumer devices in particular are very taste driven do I think that we're gonna you\\nknow go back to a world of you know giant phones with lots of buttons I don't um\\nI think that this this this technological move into kind of simpler\\nlooking devices aesthetic devices is probably permanent\\nso is this framework part of testing the MVP because what I'm struggling with this\\nespecially for Hardware products how to use these framework because initially\\nyou are going to start with something over time it well well not necessarily I mean so\\nyou're a hardware person is that is that why you're asking tell me tell me about what you're working on I'd like to\\nlike like one thing but\\nbut are embedded in Furniture yeah oh awesome right but then\\nthe technology takes time to evolve but we\", metadata={'source': '/teamspace/studios/this_studio/retrieval-augmented-generation/data/part3.txt'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db191098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "persist_directory = 'db'\n",
    "\n",
    "## here we are using OpenAI embeddings but in future we will swap out to local embeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectordb = Chroma.from_documents(documents=texts, \n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4398977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# persiste the db to disk\n",
    "vectordb.persist()\n",
    "vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67b8b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal. \n",
    "vectordb = Chroma(persist_directory=persist_directory, \n",
    "                  embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20c2abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "919454ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = retriever.get_relevant_documents(\"What is Product Company Gap?\")\n",
    "docs = retriever.invoke(\"What is Product Company Gap?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d43d34d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dd091d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the chain to answer questions \n",
    "qa_chain = RetrievalQA.from_chain_type(llm=OpenAI(), \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3def528",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cite sources\n",
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60637ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Product Company Gap is a term used to describe the challenge that companies face in transitioning from having a successful product to becoming a successful and sustainable company. This involves considerations such as go-to-market strategies, pricing, and creating a business model that allows for scalability.\n",
      "\n",
      "\n",
      "Sources:\n",
      "/teamspace/studios/this_studio/retrieval-augmented-generation/data/part1.txt\n",
      "/teamspace/studios/this_studio/retrieval-augmented-generation/data/part1.txt\n",
      "/teamspace/studios/this_studio/retrieval-augmented-generation/data/part1.txt\n",
      "/teamspace/studios/this_studio/retrieval-augmented-generation/data/part2.txt\n"
     ]
    }
   ],
   "source": [
    "# full example\n",
    "query = \"What is Product Company Gap?\"\n",
    "llm_response = qa_chain.invoke(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4cf0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To cleanup, you can delete the collection\n",
    "\n",
    "# vectordb.delete_collection()\n",
    "# vectordb.persist()\n",
    "# delete the directory\n",
    "# !rm -rf db/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
